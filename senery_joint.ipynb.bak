{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "leftgray = cv2.imread('5.jpg')\n",
    "rightgray = cv2.imread('6.jpg')\n",
    " \n",
    "hessian=400\n",
    "surf=cv2.xfeatures2d.SURF_create(hessian)\n",
    "#surf=cv2.SURF(hessian) #将Hessian Threshold设置为400,阈值越大能检测的特征就越少\n",
    "kp1,des1=surf.detectAndCompute(leftgray,None)  #查找关键点和描述符\n",
    "kp2,des2=surf.detectAndCompute(rightgray,None)\n",
    " \n",
    " \n",
    "FLANN_INDEX_KDTREE=0   #建立FLANN匹配器的参数\n",
    "indexParams=dict(algorithm=FLANN_INDEX_KDTREE,trees=5) #配置索引，密度树的数量为5\n",
    "searchParams=dict(checks=50)    #指定递归次数\n",
    "#FlannBasedMatcher：是目前最快的特征匹配算法（最近邻搜索）\n",
    "flann=cv2.FlannBasedMatcher(indexParams,searchParams)  #建立匹配器\n",
    "matches=flann.knnMatch(des1,des2,k=2)  #得出匹配的关键点\n",
    " \n",
    "good=[]\n",
    "#提取优秀的特征点\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance: #如果第一个邻近距离比第二个邻近距离的0.7倍小，则保留\n",
    "        good.append(m)\n",
    "src_pts = np.array([ kp1[m.queryIdx].pt for m in good])    #查询图像的特征描述子索引\n",
    "dst_pts = np.array([ kp2[m.trainIdx].pt for m in good])    #训练(模板)图像的特征描述子索引\n",
    "H=cv2.findHomography(src_pts,dst_pts)         #生成变换矩阵\n",
    "h,w=leftgray.shape[:2]\n",
    "h1,w1=rightgray.shape[:2]\n",
    "shft=np.array([[1.0,0,w],[0,1.0,0],[0,0,1.0]])\n",
    "M=np.dot(shft,H[0])            #获取左边图像到右边图像的投影映射关系\n",
    "dst_corners=cv2.warpPerspective(leftgray,M,(w*2,h))#透视变换，新图像可容纳完整的两幅图\n",
    "cv2.imshow('tiledImg1',dst_corners)   #显示，第一幅图已在标准位置\n",
    "dst_corners[0:h,w:w*2]=rightgray  #将第二幅图放在右侧\n",
    "#cv2.imwrite('tiled.jpg',dst_corners)\n",
    "cv2.imshow('tiledImg',dst_corners)\n",
    "cv2.imshow('leftgray',leftgray)\n",
    "cv2.imshow('rightgray',rightgray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "设图像高为h，相同部分的宽度为wx\n",
    "\n",
    "拼接后图像的宽w=wA+wB-wx\n",
    "\n",
    "因此，可以先构建一个高为h，宽为W*2的空白图像，将左图像向右平移wx，右图像粘贴在右侧。则右图像刚好覆盖左图像中的相同部分。最终拼接图像完成，完成后的图像左侧有宽度为wx的空白即为所检测出的两幅图像的相同部分，可根据需要选择是否去除。示例图如下。\n",
    "\n",
    "实现上述效果的步骤如下：\n",
    "\n",
    "1. 采用surft特征检测算法检测两幅图像的关键特征点；\n",
    "\n",
    "2. 建立FLANN匹配器，采用目前最快的特征匹配（最近邻搜索）算法FlannBasedMatcher匹配关键点\n",
    "\n",
    "3. 从所匹配的全部关键点中筛选出优秀的特征点（基于距离筛选）\n",
    "\n",
    "4. 根据查询图像和模板图像的特征描述子索引得出仿射变换矩阵\n",
    "\n",
    "5. 获取左边图像到右边图像的投影映射关系\n",
    "\n",
    "6. 透视变换将左图像放在相应的位置\n",
    "\n",
    "7. 将有图像拷贝到特定位置完成拼接\n",
    "\n",
    "\n",
    "# 实验效果根据三组图发现，只有建筑那一组最好，可能两幅图在完全平移的情况下得到的效果最好"
    "# 参考链接：https://www.cnblogs.com/xingnie/p/10230278.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
